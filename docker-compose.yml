version: "3.9"

services:
  yolov11:
    shm_size: 8gb
    build:
      context: .
      dockerfile: yolov11.Dockerfile
    container_name: v2-yolov11

    # ✅ Compose 스키마 요구대로 유지
    gpus: all

    # ✅ GPU 0만 할당 (핵심)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: ["gpu"]

    ports:
      - "8020:8020"
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - ./storage/weights:/weights
      - ./storage/artifacts/yolov11:/artifacts
      - ./storage/datasets:/datasets:ro
    environment:
      MODEL_NAME: yolov11
      PYTHONPATH: /workspace
      WEIGHTS_ROOT: /weights
      ARTIFACTS_DIR: /artifacts

      # (선택) 내부 device는 cuda:0로 쓰게 0 유지
      DEVICE: "0"

      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"

      S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_DEFAULT_REGION: us-east-1
    depends_on:
      - minio
    command: >
      uvicorn api.yolov11.server:app
      --app-dir /workspace
      --host 0.0.0.0 --port 8020
      --reload
      --reload-dir /workspace/api
      --reload-dir /workspace/src

  rtdetr:
    shm_size: 8gb
    build:
      context: .
      dockerfile: rtdetr.Dockerfile
    container_name: v2-rtdetr

    gpus: all

    # ✅ GPU 1만 할당
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: ["gpu"]

    ports:
      - "8021:8021"
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - ./storage/weights:/weights
      - ./storage/artifacts/rtdetr:/artifacts
      - ./storage/datasets:/datasets:ro
    environment:
      MODEL_NAME: rtdetr
      PYTHONPATH: /workspace
      WEIGHTS_ROOT: /weights
      ARTIFACTS_DIR: /artifacts

      # 컨테이너 내부에서 보이는 GPU는 1개 → cuda:0
      DEVICE: "0"

      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"

      S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_DEFAULT_REGION: us-east-1
    depends_on:
      - minio
    command: >
      uvicorn api.rtdetr.server:app
      --app-dir /workspace
      --host 0.0.0.0 --port 8021
      --reload
      --reload-dir /workspace/api
      --reload-dir /workspace/src

  rtm:
    shm_size: 8gb
    build:
      context: .
      dockerfile: rtm.Dockerfile
    container_name: v2-rtm

    gpus: all

    # ✅ GPU 2만 할당
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["2"]
              capabilities: ["gpu"]

    ports:
      - "8022:8022"
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - ./storage/weights:/weights
      - ./storage/artifacts/rtm:/artifacts
      - ./storage/datasets:/datasets:ro
    environment:
      MODEL_NAME: rtm
      PYTHONPATH: /workspace
      WEIGHTS_ROOT: /weights
      ARTIFACTS_DIR: /artifacts
      RTM_CONFIG: /workspace/configs/recipes/rtm/rtmdet_x_bdd100k_canon10_50e.py

      # 컨테이너 내부에서 보이는 GPU는 1개 → cuda:0
      DEVICE: "cuda:0"

      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"

      S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_DEFAULT_REGION: us-east-1
    depends_on:
      - minio
    command: >
      uvicorn api.rtm.server:app
      --app-dir /workspace
      --host 0.0.0.0 --port 8022
      --reload
      --reload-dir /workspace/api
      --reload-dir /workspace/src

  judge:
    shm_size: 8gb
    build:
      context: .
      dockerfile: judge.Dockerfile
    container_name: v2-judge
    ports:
      - "8025:8025"
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - ./script:/script:ro
      - ./logs:/logs
      - ./configs:/configs:ro
      - ./storage/artifacts/judge:/artifacts
      - ./storage/datasets:/datasets:ro
    environment:
      PYTHONPATH: /workspace
      PROJECT_ROOT: /workspace
      CONFIGS_DIR: /configs
      RUN_GT_TRAIN_SCRIPT: /script/tools/run_gt_train.py
      PYTHON_BIN: python
      YOLOV11_URL: http://yolov11:8020/infer
      RTDETR_URL: http://rtdetr:8021/infer
      RTM_URL: http://rtm:8022/infer
      S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_DEFAULT_REGION: us-east-1
      MLFLOW_TRACKING_URI: http://mlflow:5000
      ARTIFACTS_DIR: /artifacts
    depends_on:
      - yolov11
      - rtdetr
      - rtm
      - minio
      - mlflow
    command: >
      uvicorn api.judge.server:app
      --app-dir /workspace
      --host 0.0.0.0 --port 8025
      --reload
      --reload-dir /workspace/api
      --reload-dir /workspace/src
      --reload-dir /workspace/configs

  minio:
    image: minio/minio:latest
    container_name: v2-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./storage/minio:/data
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: v2-mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./storage/mlflow:/mlflow
    environment:
      MLFLOW_BACKEND_STORE_URI: sqlite:////mlflow/mlflow.db
      MLFLOW_DEFAULT_ARTIFACT_ROOT: s3://v2-artifacts
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_DEFAULT_REGION: us-east-1
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    depends_on:
      - minio
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --default-artifact-root s3://v2-artifacts
